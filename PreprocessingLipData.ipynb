{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civilian-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_dir =  '../cropped/cropped'\n",
    "data_per = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "subject-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 64, 64, 3) (1, 380928)\n",
      "(380931,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(761859,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(380928,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(761856,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(1142784,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(1523712,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(1904640,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(2285568,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(2666496,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(3047424,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(3428352,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(3809280,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(4190208,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(4571136,)\n",
      "(31, 64, 64, 3) (1, 380928)\n",
      "(4952064,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-463634db03cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "# 1. image을 같은 크기로 resize\n",
    "# 2. (Data Augmentation)\n",
    "# 3. list안에 순서대로 들어갈 수 있게\n",
    "\n",
    "# [[[~,~,~], [~~~],[~~~],[~~],[~~]],[[~~],[~~],[~~~]]]\n",
    "# x.shape = [image 갯수, frame 갯수, image_size(벡터)]\n",
    "# y.shape = [image 갯수, ]\n",
    "# data = np.array(list)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "for person in data_per:\n",
    "    if person == '.DS_Store':\n",
    "        continue\n",
    "    words_dir = os.path.join(data_dir, person) + '/words'\n",
    "    sentences = os.listdir(words_dir)\n",
    "    for sentence_id in sentences:\n",
    "        s_dir = os.path.join(words_dir, sentence_id)\n",
    "        nums = os.listdir(s_dir)\n",
    "        x_data = np.empty(3)\n",
    "        for n in nums:\n",
    "            frames_dir = os.path.join(s_dir, n)\n",
    "            frames = os.listdir(frames_dir)\n",
    "            x_data_ = np.empty(3)\n",
    "            for frame in frames:\n",
    "                img_path =f'{frames_dir}/{frame}'\n",
    "                \n",
    "                # resize, flatten, nparray\n",
    "                img = image.load_img(img_path, target_size=(64,64))\n",
    "                img_array = image.img_to_array(img)\n",
    "                img_augmented = DataAugmentation().generate(img_array, 10)\n",
    "                img_tensor = img_augmented.flatten()\n",
    "                img_tensor /= 255.\n",
    "                img_tenor = np.expand_dims(img_tensor, axis=0)\n",
    "                print(img_augmented.shape, img_tenor.shape)\n",
    "                \n",
    "                # frame 묶기\n",
    "                if frame == 'color_001.jpg':\n",
    "                    x_data_ = img_tensor\n",
    "                else:\n",
    "                    x_data_ = np.concatenate([x_data_, img_tensor], axis=0)\n",
    "                    \n",
    "                print(x_data_.shape)\n",
    "                \n",
    "            # 이미지 통합\n",
    "            x_data_ = np.expand_dims(x_data_, axis = 0)\n",
    "            if n == '01':\n",
    "                x_data = x_data_\n",
    "            else:\n",
    "                x_data = np.concatenate([x_data, x_data_], axis=0)\n",
    "            print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "engaging-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://m.blog.naver.com/PostView.nhn?blogId=isu112600&logNo=221582003889&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class DataAugmentation:\n",
    "\n",
    "#     def __init__(self, img, count):\n",
    "#         self.data = np.expand_dims(img, axis=0)\n",
    "#         self.augmentedData = np.empty(3)\n",
    "#         self.count = count\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def generate(self, img, count):\n",
    "        self.data = np.expand_dims(img, axis=0)\n",
    "        self.augmentedData = self.data\n",
    "        \n",
    "        self.width_shift_range(self, count)\n",
    "        self.height_shift_range(self, count)\n",
    "        self.random_rotation(self, count)\n",
    "        \n",
    "        return self.augmentedData\n",
    "    \n",
    "    \n",
    "    # 좌우로 shift\n",
    "    def width_shift_range(self, count):\n",
    "        # generatior 생성\n",
    "        datagen = ImageDataGenerator(width_shift_range=[-20,20])\n",
    "        \n",
    "        # iterator 준비\n",
    "        it = datagen.flow(self.data, batch_size=1)\n",
    "        \n",
    "        for i in range(count):\n",
    "            x_batch = it.next()\n",
    "            self.augmentedData = np.concatenate([self.augmentedData, x_batch], axis=0)\n",
    "    \n",
    "    # 상하로 shift\n",
    "    def height_shift_range(self, count):\n",
    "        # generatior 생성\n",
    "        datagen = ImageDataGenerator(height_shift_range=0.5)\n",
    "        \n",
    "        # iterator 준비\n",
    "        it = datagen.flow(self.data, batch_size=1)\n",
    "        \n",
    "        for i in range(count):\n",
    "            x_batch = it.next()\n",
    "            self.augmentedData = np.concatenate([self.augmentedData, x_batch], axis=0)\n",
    "            \n",
    "    # 랜덤 각도 돌리기\n",
    "    def random_rotation(self, count):\n",
    "        # generatior 생성\n",
    "        datagen = ImageDataGenerator(rotation_range=90)\n",
    "        \n",
    "        # iterator 준비\n",
    "        it = datagen.flow(self.data, batch_size=1)\n",
    "        \n",
    "        for i in range(count):\n",
    "            x_batch = it.next()\n",
    "            self.augmentedData = np.concatenate([self.augmentedData, x_batch], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
